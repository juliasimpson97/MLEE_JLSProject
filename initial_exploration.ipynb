{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d799a93e-ac5b-4192-998f-a08682755d35",
   "metadata": {},
   "source": [
    "# *WORKFLOW MAPPING*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08479b7-c427-4d10-92d9-f372144e57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#typical ML imports (from NN example ipynb)\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "from glob import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import Sequential\n",
    "from utils import * \n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "plt.rcParams['savefig.dpi'] = 400\n",
    "plt.rcParams['font.size'] = 13\n",
    "plt.rcParams[\"legend.frameon\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6322df88-a4b8-4961-a9f0-61ecdd37e03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#additional ML imports (from RF example ipynb)\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from utils import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6d22e2-e561-406f-9386-59a75c6b1318",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Data Import "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a5ccb7-a6bc-423f-ae88-5b8eff0bad45",
   "metadata": {},
   "source": [
    "### 1.a. Import all predictor and \"true\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c16fb46-634b-4be0-8944-5f9e2f1aa61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull and save into 1_raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07734364-3e18-4f2e-acee-7ed04d226f59",
   "metadata": {},
   "source": [
    "## 2. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0ef0b7-6dc2-4875-8938-7594cafa4caa",
   "metadata": {},
   "source": [
    "### 2.a. Split into training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9870b9df-0930-4a93-92d9-7b2b09db25ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull from 1_raw_data and place in 2_proc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83254a51-9402-4f42-8d28-adcf5201207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create directories:\n",
    "cwd = os.getcwd()\n",
    "\n",
    "train_path = os.path.join(cwd,'Data','train_val')\n",
    "test_path  = os.path.join(cwd,'Data','test')\n",
    "\n",
    "make_dir(train_path)\n",
    "make_dir(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d60afa-693c-4928-a04f-cc8503706af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "train_files = [\"historical\", \"ssp585\", \"ssp126\", \"ssp370\",\"hist-aer\",\"hist-GHG\"]\n",
    "X_train_xr, X_length  = prepare_predictor(train_files,train_path)\n",
    "y_train_xr, y_length  = prepare_predictand(train_files,train_path)\n",
    "\n",
    "# Test set\n",
    "X_test_xr, _ = prepare_predictor('ssp245', data_path=test_path,time_reindex=False)\n",
    "y_test_xr, _ = prepare_predictand('ssp245',data_path=test_path,time_reindex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f849b20b-0d08-45fe-aff8-a76c5f60b349",
   "metadata": {},
   "source": [
    "### 2.b. Organize all required variables into a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8064a820-b20f-41d8-8d5d-277eb1d7076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame({\"CO2\": X_train_xr[\"CO2\"].data,\n",
    "                           \"CH4\": X_train_xr[\"CH4\"].data\n",
    "                          }, index=X_train_xr[\"CO2\"].coords['time'].data)\n",
    "\n",
    "X_test_df  = pd.DataFrame({\"CO2\": X_test_xr[\"CO2\"].data,\n",
    "                           \"CH4\": X_test_xr[\"CH4\"].data\n",
    "                          }, index=X_test_xr[\"CO2\"].coords['time'].data)\n",
    "\n",
    "\n",
    "y_train_df = y_train_xr[\"tas\"].stack(dim=[\"latitude\", \"longitude\"])\n",
    "y_train_df = pd.DataFrame(y_train_df.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1099936-8c5d-4158-b39d-03ba6895ce75",
   "metadata": {},
   "source": [
    "### NOTE: Additional step for training (and test?) datasets: need to filter out predictor information where don't have SOCAT? or simply leave/will be fine with lat/lon coordinates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241caee-078e-4aac-81e8-e540f82c7377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a6be189-d924-4387-ad2d-23c44bf2eda1",
   "metadata": {},
   "source": [
    "### 2.c. Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd7cd7-4103-4ddd-8ba6-16317d776835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "mean, std = X_train_df.mean(), X_train_df.std()\n",
    "\n",
    "X_train_df   = (X_train_df - mean)/std\n",
    "X_test_df    = (X_test_df - mean)/std\n",
    "\n",
    "X_train = X_train_df.to_numpy()\n",
    "y_train = y_train_df.to_numpy()\n",
    "X_test = X_test_df.to_numpy()\n",
    "\n",
    "print(X_train.shape,y_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4396094-ffb9-4d86-aa3b-c1011f5557aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the NaN values in a mask, will need to mask out all predictors where don't have SOCAT?\n",
    "mask = ~np.isnan(SOCAT.isel(time=0)) #isel(time=0) won't work here though because observations could be at different times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be48483-9cc1-4b71-be1c-713e7a5ddffe",
   "metadata": {},
   "source": [
    "## 3. Train different machine learning methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc3ed8f-16ab-4c62-bbc5-576d9c3b9b95",
   "metadata": {},
   "source": [
    "### 3.a. Random Forest (to be used as a baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fdb2cd7-e360-4dc3-9537-ff981c504771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name everything with RF\n",
    "# will be Notebook A in 3_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175fab0b-a792-44c0-97ac-c74b8438b433",
   "metadata": {},
   "source": [
    "#### 3.a.i. Building and Training the RF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4df2da-9536-4fc9-9273-d262543fd9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try using cross-validation to get the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb7f182-f738-477b-a479-dcd5caf00020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 300, num = 5)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5,55, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [5, 10, 15, 25]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [4, 8, 12,16]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112356dd-2317-4aab-a2f8-34daa47836f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af89cc1-a007-48f8-8b4b-db572e93485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg0 = RandomForestRegressor(random_state=0)\n",
    "# perform cross validation\n",
    "rf_random0 = RandomizedSearchCV(estimator = reg0, param_distributions = random_grid, \n",
    "                                n_iter = 5, cv = 3, verbose=2, n_jobs = -1)\n",
    "rf_tas = rf_random0.fit(X_train,y_train)\n",
    "\n",
    "print(\"The best hyperparameters: \\n\",rf_tas.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af4ddfa-b30c-49c8-b2f2-99fc389593d2",
   "metadata": {},
   "source": [
    "#### 3.a.ii. Testing the RF Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4381ae-8796-4909-b375-151c2c0459da",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.b. eXtreme Gradient Boosting (to compare performance to other methods from group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19178374-d5be-4e8a-b479-46dff12951e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name everything with XGB\n",
    "# will be Notebook B in 3_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319ef452-5d57-46c5-b826-23268860b5e7",
   "metadata": {},
   "source": [
    "#### 3.b.i. Building and Training the XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d90ab3-a5da-48a6-979f-34003a2c32ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bf573fc-7775-4418-90d7-6e98e8b808c9",
   "metadata": {},
   "source": [
    "#### 3.b.ii. Testing the XGB Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8d6a5a-6ed5-495c-b179-7f13cd554e66",
   "metadata": {},
   "source": [
    "### 3.c. Neural Network (to experiment with hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4de3531-4e6f-4f6d-8db4-84e30401e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name everything with NN\n",
    "# will be Notebook C in 3_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5f399d-acac-4970-a5e4-40d385e950a4",
   "metadata": {},
   "source": [
    "#### 3.c.i. Building and Training the NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3de2fbf4-86e2-479e-86e7-696f59094627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The NN input layer has # NOTE that number of input layer neurons must correspond to number of predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ed0b5a-ae9d-4c91-8a75-fcb0d31e874c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set hyperparameters\n",
    "n_neuron       = 64\n",
    "activation     = 'relu'\n",
    "num_epochs     = 50\n",
    "learning_rate  = 0.001\n",
    "minibatch_size = 64\n",
    "model_num      = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b330136-28bd-4051-a51a-e681d6932882",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(n_neuron,  activation=activation,input_shape=(X_train.shape[1],))) #  the 1st hidden layer \n",
    "model.add(Dense(n_neuron,  activation=activation)) # the 2nd hidden layer\n",
    "model.add(Dense(n_neuron,  activation=activation)) # the 3rd hidden layer\n",
    "model.add(Dense(y_train.shape[1],  activation='linear')) # the output layer\n",
    "\n",
    "\n",
    "model.compile(loss='mse',optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3908696c-15cf-4143-b2be-9fcf179283a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9987352f-b26a-4129-8bf1-39ac481ff56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after training, save:\n",
    "model_path = os.path.join(cwd,'saved_model')\n",
    "make_dir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca7a8cc-9de7-4634-a1f7-dab82cd6b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(model_path,'NN_model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1016f61f-1eb9-47e1-bce5-56ea34272bca",
   "metadata": {},
   "source": [
    "#### 3.c.ii. Testing the NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4befa5-b232-49b0-b0ff-f8f397d6f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then reload before start working with test data\n",
    "model = load_model(os.path.join(model_path,'NN_model.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39360a71-ef24-4b86-ace0-b4953201be35",
   "metadata": {},
   "source": [
    "### 3.d. Other (to explore further if time permits)\n",
    "#### *If proceed, choose among the following:*\n",
    "- support vector regression (SVR); \n",
    "- long short-term memory (LSTM) network; or \n",
    "- an ensemble of RF, NN, and XGB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "106f4d9a-7bc7-4f7d-adda-5df3c951189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if do, will be Notebook D in 3_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd829df-c777-4e92-941b-fc1a1741d873",
   "metadata": {},
   "source": [
    "## 3. Figures for Results and Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb6901d3-bebc-4eb9-884e-2ae31883fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize/compare all test figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5439a16-3fc1-4ab8-bf26-59f76ec22848",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'newvariable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#At end, can create function to_netcdf so can export all data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnewvariable\u001b[49m\u001b[38;5;241m.\u001b[39mto_netcdf(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mnewvariable.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpinfo\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto_netcdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'newvariable' is not defined"
     ]
    }
   ],
   "source": [
    "#At end, can create function to_netcdf so can export all data\n",
    "newvariable.to_netcdf('data\\\\newvariable.nc')\n",
    "# more info: https://docs.xarray.dev/en/stable/generated/xarray.Dataset.to_netcdf.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fromML",
   "language": "python",
   "name": "fromml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
